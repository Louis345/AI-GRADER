const { exec } = require("child_process");
const util = require("util");
const fs = require("fs").promises;
const path = require("path");

// Promisify exec for async/await
const execPromise = util.promisify(exec);

/**
 * Fetches the transcript from a YouTube video using yt-dlp
 * @param {string} url - The YouTube video URL
 * @returns {Promise<string[]>} Array of unique transcript text segments
 */
async function getYouTubeTranscript(url) {
  try {
    console.log(`üé¨ Fetching YouTube transcript for: ${url}`);
    console.log(`üõ†Ô∏è Returning array of unique text segments`);

    // Extract video ID
    const regex =
      /(?:youtube\.com\/(?:[^\/]+\/.+\/|(?:v|e(?:mbed)?)\/|.*[?&]v=)|youtu\.be\/)([^"&?\/\s]{11})/;
    const match = url.match(regex);
    if (!match) {
      throw new Error("Invalid YouTube URL format");
    }
    const videoId = match[1];
    console.log(`üìπ Video ID: ${videoId}`);

    // Temporary directory for caption file
    const tempDir = path.join(__dirname, "temp");
    await fs.mkdir(tempDir, { recursive: true });

    // Run yt-dlp to download English captions
    const outputFile = path.join(tempDir, `${videoId}`);
    const venvPython = path.join(
      __dirname,
      "..",
      "..",
      "venv",
      "bin",
      "python3"
    );
    console.log(
      `üîç Running command: ${venvPython} -m yt_dlp --write-auto-sub --sub-lang en --skip-download --sub-format vtt -o "${outputFile}" ${url}`
    );
    const { stdout, stderr } = await execPromise(
      `${venvPython} -m yt_dlp --write-auto-sub --sub-lang en --skip-download --sub-format vtt -o "${outputFile}" ${url}`
    );
    console.log(`üìú yt-dlp stdout: ${stdout}`);
    if (stderr) console.log(`‚ö†Ô∏è yt-dlp stderr: ${stderr}`);

    // Check if VTT file exists
    const vttFile = `${outputFile}.en.vtt`;
    try {
      await fs.access(vttFile);
    } catch {
      throw new Error("VTT file not generated by yt-dlp");
    }

    // Read and parse the VTT file
    const vttContent = await fs.readFile(vttFile, "utf-8");
    console.log(
      `üìÑ VTT content (first 500 chars): ${vttContent.slice(0, 500)}`
    );

    // Parse VTT to extract text
    const lines = vttContent.split("\n");
    const transcript = [];
    let currentText = [];
    const seenText = new Set(); // Global deduplication

    for (let i = 0; i < lines.length; i++) {
      let line = lines[i].trim();
      console.log(`üî¨ Processing line ${i + 1}: ${line}`);

      // Skip headers, metadata, and timestamps
      if (
        line.startsWith("WEBVTT") ||
        line.startsWith("Kind:") ||
        line.startsWith("Language:") ||
        line.match(/align:start position:/) ||
        line.match(/^\d{2}:\d{2}:\d{2}\.\d{3}\s-->\s\d{2}:\d{2}:\d{2}\.\d{3}$/)
      ) {
        // Process accumulated text before timestamp
        if (currentText.length > 0) {
          let rawText = currentText.join(" ");
          console.log(`üßº Raw text: ${rawText}`);
          let cleanedText = rawText
            .replace(/<[^>]+>/g, "") // Remove tags
            .replace(/\s+/g, " ") // Normalize spaces
            .trim();
          console.log(`üßπ Cleaned text: ${cleanedText}`);

          // Add valid text to transcript
          if (
            cleanedText &&
            !["[Music]", "Heat.", "Heat. Heat. Heat."].includes(cleanedText) &&
            !seenText.has(cleanedText)
          ) {
            console.log(`üìù Adding segment: ${cleanedText}`);
            transcript.push(cleanedText);
            seenText.add(cleanedText);
          } else {
            console.log(
              `‚ö†Ô∏è Skipped segment: cleanedText=${cleanedText}, duplicate=${seenText.has(
                cleanedText
              )}, music=${["[Music]", "Heat.", "Heat. Heat. Heat."].includes(
                cleanedText
              )}`
            );
          }
          currentText = [];
        }
        continue;
      }

      // Accumulate non-empty text lines
      if (line) {
        console.log(`üì• Adding to currentText: ${line}`);
        currentText.push(line);
      }
    }

    // Process any remaining text
    if (currentText.length > 0) {
      let rawText = currentText.join(" ");
      console.log(`üßº Raw text (final): ${rawText}`);
      let cleanedText = rawText
        .replace(/<[^>]+>/g, "")
        .replace(/\s+/g, " ")
        .trim();
      console.log(`üßπ Cleaned text (final): ${cleanedText}`);

      if (
        cleanedText &&
        !["[Music]", "Heat.", "Heat. Heat. Heat."].includes(cleanedText) &&
        !seenText.has(cleanedText)
      ) {
        console.log(`üìù Adding segment (final): ${cleanedText}`);
        transcript.push(cleanedText);
        seenText.add(cleanedText);
      } else {
        console.log(
          `‚ö†Ô∏è Skipped final segment: cleanedText=${cleanedText}, duplicate=${seenText.has(
            cleanedText
          )}, music=${["[Music]", "Heat.", "Heat. Heat. Heat."].includes(
            cleanedText
          )}`
        );
      }
    }

    // Clean up temporary file
    await fs.unlink(vttFile).catch(() => {});

    if (transcript.length === 0) {
      throw new Error("No transcript extracted from VTT file");
    }

    console.log(
      `‚úÖ Transcript: ${transcript.length} segments, ~${transcript.reduce(
        (sum, text) => sum + text.split(/\s+/).length,
        0
      )} words`
    );
    return transcript;
  } catch (error) {
    console.error(`‚ùå Error: ${error.message}`);
    return [
      `VIDEO_SUBMITTED_TRANSCRIPT_ERROR: Failed to extract transcript for ${url}. Error: ${error.message}. GRADING RECOMMENDATION: Partial credit, manually review video at ${url}`,
    ];
  }
}

module.exports = { getYouTubeTranscript };
